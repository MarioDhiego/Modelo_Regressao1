[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Técnicas de Machine Learning no R",
    "section": "",
    "text": "Prefácio\nUm dos mais relevantes desafios, no atual cenário competitivo, refere-se à efetiva aplicação das técnicas analíticas no equacionamento e resolução dos problemas empresariais. O desenvolvimento de modelos de análises aplicados à realidade empresarial tornou-se uma competência crítica em todos os setores de atividade econômica. Esta habilidade é imperativa na esfera governamental e nas organizações sem finalidades lucrativas.\nO profissionais que atuam nos projetos de natureza analítica enfrentam desafios peculiares. Em geral, as organizações demandam soluções práticas e de rápida implantação. Por outro lado, existe um ritmo intenso de geração de novas Frameworks, Bibliotecas e ferramentas de software bem como do aperfeiçoamento contínuo dos algoritmos de análise.\nAs técnicas analíticas aqui expostas são aquelas que devem fazer parte do repertório obrigatório da Análise de Dados.\nEste livro foi escrito com objetivo de permitir que estudantes e pesquisadores entendam e apliquem diferentes algoritmos de Machine Learning, sem apronfundar-se nas teorias que os fundamentam. Preferiu-se apresentar os principais conceitos de forma intuitiva, para que o usuário compreenda a lógica de cada algoritmo, para que finalidade deve ser utilizado, quais os passos a seguir para aplicá-lo corretamente utilizando o sotware R e suas vantagens e limitações quando comparado com outros algritmos que podem ser utilizados no mesmo problema."
  },
  {
    "objectID": "exploratoria.html#variáveis-qualitativas",
    "href": "exploratoria.html#variáveis-qualitativas",
    "title": "1  Análise Exploratória",
    "section": "1.1 Variáveis Qualitativas",
    "text": "1.1 Variáveis Qualitativas\n\n1.1.1 Tabelas de Frequência: Simples\n\ntable(mercado2$CARGO)\n\n\nAUXILIAR  DIRETOR  GERENTE \n      37       12       30 \n\ntable(mercado2$EDUCAÇÃO)\n\n\nSECUNDÁRIO   SUPERIOR \n        15         64 \n\ntable(mercado2$LOCAL)\n\n\n CAPITAL INTERIOR \n      44       35 \n\n\n\n\n1.1.2 Tabelas de Frequência: Proporção\n\nprop.table(table(mercado2$CARGO))\n\n\n AUXILIAR   DIRETOR   GERENTE \n0.4683544 0.1518987 0.3797468 \n\nprop.table(table(mercado2$EDUCAÇÃO))\n\n\nSECUNDÁRIO   SUPERIOR \n 0.1898734  0.8101266 \n\nprop.table(table(mercado2$LOCAL))\n\n\n CAPITAL INTERIOR \n0.556962 0.443038"
  },
  {
    "objectID": "exploratoria.html#variáveis-quantitativas",
    "href": "exploratoria.html#variáveis-quantitativas",
    "title": "1  Análise Exploratória",
    "section": "1.2 Variáveis Quantitativas",
    "text": "1.2 Variáveis Quantitativas\n\n1.2.1 Medidas Resumo Geral\n\nsummary(mercado2$IDADE)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  30.00   43.50   49.00   49.62   55.50   72.00 \n\nsummary(mercado2$TEMPOCASA)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n    0.0     3.5    12.0    10.8    16.5    25.0 \n\nsummary(mercado2$SALARIO)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   4187    4894    5660    5693    6270    7481 \n\n\n\n\n1.2.2 Interpretação p/ Salário\n\no 1º quartil(1 st Qu.) indica que 25% dos funcionários têm renda salarial menor ou igual a R$ 4.894 e o 3º quartil(3 rd Qu.) indica que 75% têm renda menor ou igual a R$ 6.306.\nEstes dois valores indicam que 50% dos funcionários tem renda nesse intervalo, o que já nos dá uma idéia de variabilidade da Renda.\nQuanto maior a diferença entre o 3º e o 1º quartil, maior a dispersão da variável.\n\n\n\n\n\n\n\n\n1.2.3 Relação Gráfica: Variáveis Quantitativas\nA função pairs.panels() do pacote psych no R gera um figura com os gráficos de dispersão 2 a 2, os histogramas de cada variável e as correlações das variaveis 2 a 2.\n\nlibrary(psych)\npairs.panels(mercado,\n             smoother = TRUE)"
  },
  {
    "objectID": "intro.html#modelo-de-regressão-simples",
    "href": "intro.html#modelo-de-regressão-simples",
    "title": "2  Regressão Linear",
    "section": "2.1 Modelo de Regressão Simples",
    "text": "2.1 Modelo de Regressão Simples\nA Técnica de Regressão Linear é uma das mais conhecida e utilizadas na Estatística. È a porta de entrada para diversos modelos preditivos mais sofisticados, já que muitos destes usam conceitos também utilizados na regressão linear. Essencialmente, a regressão linear pode ser utilizada para prever o valor de uma variável quantitativa (dependente) em função das outras variáveis (independentes ou preditoras)."
  },
  {
    "objectID": "intro.html#dataset",
    "href": "intro.html#dataset",
    "title": "2  Regressão Linear",
    "section": "2.2 Dataset",
    "text": "2.2 Dataset\nPara ilustrar a regressão simples, vamos começar com um exemplo em que queremos estudar a relação entre idade (variável preditora \\(X_{1}\\)) e Salário (variável dependente Y) com uma amostra de 80 funcionários do Supermercadp Formosa.\n\nLocal: Supermercado Formosa\nAmostra: 80 pessoas\nID : Indetidade do Funcionário\nEDUCAÇÃO : Nível Educacional do Funcionário\nCARGO : Cargo do Funcionário\nLOCAL : Local onde Atua o Funcionário\nIDADE : Idade em anos Completos do Funcionário\nTEMPOCASA : Tempo de Casa\nSALARIO : Salário Mensal do Funcionário em R$\n\nPara ilustrar a regressão simples, vamos começar com um exemplo em que queremos estudar a relação entre idade (variável preditora \\(X_{1}\\)) e Salário (variável dependente Y) com uma amostra de 80 funcionários do Supermercadp Formosa.\nVamos assumir que o salário varia linearmente conforme a idade. Matematicamente, diremos que o salário é uma função linear da idade: salário = \\(Salário \\ = \\ \\beta_{0}+\\beta_{1}*Idade\\). Entretanto, sabemos que esta relação não é determinística, isto é, não necessariamente a diferença salarial entre uma pessoa com 30 anos e outra com 31 será \\(\\beta_{1}\\). Isso ocorre porque há outros fatores que interferem no salário e não estão incluídos no modelo. Este ruído será representado por um termo de erro do modelo:\n\\[ Salário = \\beta_{0} + \\beta_{1} * Idade + erro\\]\nNO modelo de regressão simples tradicional, o termo de erro tem valor esperado igual a7 zero, e isso implica no salário médio das pessoas com determinada idade, denotado por E(Salário), dado pela parte determinística da equação:\n\\[ E(Salário) = \\beta_{0} + \\beta_{1} * Idade\\]\n\\(\\beta_{0} + \\beta_{1}\\) são parâmetros do modelo e podem ser estimados a partir dos dados da amostra. NO exemplo , usaremos os dados amostrais para estimar esses parâmetros. o Primeiro passo e construir um gráfico de dispersão em que colocamos a idade no eixo x e o salário no eixo y.\n\n\n\n\n\n\n2.2.1 Gráfico de Dispersão Geral\nO script utilizado para gerar o gráfico de dispersão no R é mostrado a seguir:\n\nlibrary(ggplot2)\nlibrary(plotly)\nlibrary(readxl)\n\nmercado &lt;- read_excel('mercado.xlsx')\n\nPlot2 &lt;- ggplot(mercado, aes(x=IDADE, y= SALARIO))+\n  geom_point(size = 3.5, \n             pch = 21, \n             col = 'black',\n             fill = 'red')+\n  geom_smooth(method=\"lm\", \n              se= TRUE)+\n  theme_bw()+\n  labs(x=\"IDADE\", \n       y=\"SALÁRIO\", \n       title=\"Diagrama de Dispersão Geral\", \n       subtitle = \"Renda Salarial\")\nggplotly(Plot2)\n\n\n\n\n\nO gráfico mostra originalmente um ponto muito distante dos demais, no qual é o salário de um dos diretores da Empresa que ganha R$ 12.465,80\n\nlibrary(readxl)\n\nmercado2 &lt;- read_excel('mercado2.xlsx')\n\nO script utilizado para gerar o gráfico de dispersão no R sem a observação 69 correspondente a (60 anos; R$ 12.465,80) é mostrado a seguir:\n\n\n\n\n\n\n\n2.2.2 Gráfico de Dispersão sem Outlier 69º\n\nlibrary(ggplot2)\nlibrary(plotly)\nlibrary(readxl)\n\nmercado2 &lt;- read_excel('mercado2.xlsx')\n\nPlot3 &lt;- ggplot(mercado2, aes(x=IDADE, y= SALARIO))+\n  geom_point(size = 3.5, \n             pch = 21, \n             col = 'black',\n             fill = 'red')+\n  geom_smooth(method=\"lm\", \n              se= TRUE)+\n  theme_bw()+\n  labs(x=\"IDADE\", \n       y=\"SALÁRIO\", \n       title=\"Diagrama de Dispersão sem Outliers\", \n       subtitle = \"Renda Salarial\")\nggplotly(Plot3)\n\n\n\n\n\nO gráfico mostra que há uma tendência de crescimento do salário quando a idade aumenta, ilustrado pela reta inclinada, que chamaremos de reta de mínimos quadrados."
  },
  {
    "objectID": "intro.html#reta-de-mínimos-quadrados",
    "href": "intro.html#reta-de-mínimos-quadrados",
    "title": "2  Regressão Linear",
    "section": "2.3 Reta de Mínimos Quadrados",
    "text": "2.3 Reta de Mínimos Quadrados\nA seguir, vamos ver como encontrar a reta que estabelece uma relação entre as duas variáveis:\n\\[ \\hat{y} = \\hat{\\beta_{0}} + \\hat{\\beta_{1}x}\\]\nO símbolo “^” em \\(\\beta_{0}\\) e \\(\\beta_{1}\\) indica que estamos estimando os parâmetros do modelo populacional , já que contaremos apenas com dados amostrais no nosso cálculo. \\(\\hat{y}\\) é o valo previsto do salário médio dos funcionários com idade “x”.\nO objetivo é obter estimadores \\(\\hat{\\beta_{0}}\\) e \\(\\hat{\\beta_{1}}\\), isto é, a reta, que melhor se ajusta aos dados. Como critério de ajuste utilizaremos a “Soma de Quadrados dos Resíduos” (SQR), definida a seguir. O resíduo da7 observação “i” da amostra é a diferença entre o seu valor observado \\(y_{i}\\) e o valor previsto \\(\\hat{y}_{i}\\).\n\\[ SQR = min \\sum_{i=1}^{n} (y_{i}-\\hat{y}_{i})^{2} = min \\sum_{i=1}^{n} e_{i}^{2}\\]\nem que \\(e_{i}\\) é o resíduo da observação “i”."
  },
  {
    "objectID": "intro.html#coeficiente-de-regressão-linear",
    "href": "intro.html#coeficiente-de-regressão-linear",
    "title": "2  Regressão Linear",
    "section": "2.4 Coeficiente de Regressão Linear",
    "text": "2.4 Coeficiente de Regressão Linear\nPara fazer uma análise de regressão no R, usaremos a função lm, do pacote basic, e os dados do Supermercado Formosa. A sintaxe para rodar a regressão linear simples é lm(y~x).\n\nModelo1 = lm(mercado$SALARIO~mercado$IDADE)\nsummary(Modelo1)\n\n\nCall:\nlm(formula = mercado$SALARIO ~ mercado$IDADE)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1213.0  -505.3   -65.7   340.9  5872.4 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    1818.11     504.51   3.604  0.00055 ***\nmercado$IDADE    79.59       9.96   7.991  9.8e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 849.4 on 78 degrees of freedom\nMultiple R-squared:  0.4501,    Adjusted R-squared:  0.4431 \nF-statistic: 63.86 on 1 and 78 DF,  p-value: 9.795e-12\n\n\nNa saída acima podemos ver os estimadores \\(\\hat{\\beta_{0}}\\) e \\(\\hat{\\beta_{1}}\\) (estimate), seus erros padrão (Std. Error), a estatística t (t value) e o valor-p do teste de hipótese (Pr(&gt;|t|)).\nOs etimadores \\(\\hat{\\beta_{0}}\\) e \\(\\hat{\\beta_{1}}\\) possuem um erro padrão que depende de vários fatores, entre eles o tamanho da amostra e o desvio-padrão do erro do modelo. Com esses valores podemos construir uma estimativa intervalar, com determinado nível de confiança, para os parâmetros populacionais desconhecidos \\(\\beta_{0}\\) e \\(\\beta_{1}\\).\n\nModelo2 = lm(mercado2$SALARIO~mercado2$IDADE)\nsummary(Modelo2)\n\n\nCall:\nlm(formula = mercado2$SALARIO ~ mercado2$IDADE)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1177.94  -445.50   -14.98   417.77  1263.66 \n\nCoefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    2165.813    310.449   6.976 9.21e-10 ***\nmercado2$IDADE   71.083      6.144  11.569  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 520.2 on 77 degrees of freedom\nMultiple R-squared:  0.6348,    Adjusted R-squared:   0.63 \nF-statistic: 133.8 on 1 and 77 DF,  p-value: &lt; 2.2e-16\n\n\nA presença desse outlier tem consequências importantes para o resultado da regressão. Os valores de \\(\\hat{\\beta}_{0}\\) e \\(\\hat{\\beta}_{1}\\) mudam de (1818,11; 79,59) para (2165,81; 71,08), respectivamente, o que faz com que os valores previstos também mudem, especialmente nos extremos, isto é, para idades muito baixas e muito altas. Isso significa que esse ponto, além de outlier, é um ponto influente, isto é, a presença dele muda as estimativas do modelo.\nNa linguagem R, para obter o intervalo de 95% de confiança para a inclinação da reta, utiliza-se o script:\n\nconfint(Modelo1, \"IDADE\", level = 0.95)\n\n      2.5 % 97.5 %\nIDADE    NA     NA"
  },
  {
    "objectID": "intro.html#previsão",
    "href": "intro.html#previsão",
    "title": "2  Regressão Linear",
    "section": "2.5 Previsão",
    "text": "2.5 Previsão\nPara fazer a previsão do salário usando a linguagem R, pode-se utilizar a função predict. Por exemplo, que estamos interessados prever o salário de um funcionário de 40 anos e outro de 50 anos.\nO script no R é dado a seguir:\n\nNovaIdade = data.frame(IDADE = c(40,50))\n\npredict(Modelo1, \n        newdata = NovaIdade, \n        interval = \"prediction\"\n        )\n\n        fit      lwr      upr\n1  4205.757 2459.748 5951.766\n2  4364.933 2627.389 6102.477\n3  4444.521 2710.885 6178.158\n4  4524.109 2794.162 6254.057\n5  4683.286 2960.056 6406.516\n6  4762.874 3042.670 6483.078\n7  4762.874 3042.670 6483.078\n8  4762.874 3042.670 6483.078\n9  4842.462 3125.060 6559.864\n10 4842.462 3125.060 6559.864\n11 4922.050 3207.225 6636.875\n12 4922.050 3207.225 6636.875\n13 5001.638 3289.165 6714.111\n14 5001.638 3289.165 6714.111\n15 5001.638 3289.165 6714.111\n16 5001.638 3289.165 6714.111\n17 5160.815 3452.364 6869.265\n18 5240.403 3533.621 6947.184\n19 5240.403 3533.621 6947.184\n20 5240.403 3533.621 6947.184\n21 5319.991 3614.650 7025.332\n22 5319.991 3614.650 7025.332\n23 5399.579 3695.449 7103.709\n24 5399.579 3695.449 7103.709\n25 5399.579 3695.449 7103.709\n26 5399.579 3695.449 7103.709\n27 5399.579 3695.449 7103.709\n28 5399.579 3695.449 7103.709\n29 5479.167 3776.017 7182.317\n30 5479.167 3776.017 7182.317\n31 5479.167 3776.017 7182.317\n32 5479.167 3776.017 7182.317\n33 5479.167 3776.017 7182.317\n34 5558.755 3856.356 7261.154\n35 5558.755 3856.356 7261.154\n36 5558.755 3856.356 7261.154\n37 5558.755 3856.356 7261.154\n38 5638.343 3936.464 7340.223\n39 5638.343 3936.464 7340.223\n40 5717.931 4016.341 7419.522\n41 5717.931 4016.341 7419.522\n42 5797.520 4095.987 7499.052\n43 5797.520 4095.987 7499.052\n44 5797.520 4095.987 7499.052\n45 5797.520 4095.987 7499.052\n46 5797.520 4095.987 7499.052\n47 5877.108 4175.401 7578.814\n48 5877.108 4175.401 7578.814\n49 5877.108 4175.401 7578.814\n50 5956.696 4254.585 7658.806\n51 5956.696 4254.585 7658.806\n52 5956.696 4254.585 7658.806\n53 5956.696 4254.585 7658.806\n54 6036.284 4333.538 7739.029\n55 6115.872 4412.261 7819.483\n56 6195.460 4490.753 7900.167\n57 6195.460 4490.753 7900.167\n58 6195.460 4490.753 7900.167\n59 6195.460 4490.753 7900.167\n60 6275.048 4569.016 7981.081\n61 6275.048 4569.016 7981.081\n62 6354.636 4647.049 8062.224\n63 6434.225 4724.854 8143.595\n64 6434.225 4724.854 8143.595\n65 6513.813 4802.430 8225.195\n66 6593.401 4879.780 8307.021\n67 6593.401 4879.780 8307.021\n68 6593.401 4879.780 8307.021\n69 6593.401 4879.780 8307.021\n70 6752.577 5033.802 8471.352\n71 6832.165 5110.476 8553.854\n72 6911.753 5186.927 8636.580\n73 6991.341 5263.156 8719.527\n74 6991.341 5263.156 8719.527\n75 6991.341 5263.156 8719.527\n76 6991.341 5263.156 8719.527\n77 7150.518 5414.955 8886.081\n78 7309.694 5565.882 9053.506\n79 7389.282 5641.023 9137.541\n80 7548.458 5790.668 9306.249\n\n\nPode-se concluir, que um funcionário de 40 anos terá um salário entre R$  e R$  com 95% de probabilidade."
  },
  {
    "objectID": "intro.html#análise-de-resíduo",
    "href": "intro.html#análise-de-resíduo",
    "title": "2  Regressão Linear",
    "section": "2.6 Análise de Resíduo",
    "text": "2.6 Análise de Resíduo\nOs Testes de hipóteses anteriores só têm validade se as suposições do modelo estiverem satisfeitas. As suposições são as mesmas do modelo de regressão simples ou multipla: o erro deve ter distribuiçao normal com média 0, variância constante e independentes.\nExistem diversos pacotes na linguagem R para fazer a análise dos resíduos, mas será enfatizado apenas os gráficos mai comuns, que podem ser feitos sem a instalação de nehhum pacote adicional.\nO script a seguir cria os gráficos para regressão linear simples com n=80.\n\npar(mfrow=c(2,2))\nplot(Modelo1)\n\n\n\n\nO primeiro gráfico é chamado de (Residuals vs Fitted) mostra que a observação 69 tem um resíduo extremamente alto, considerando um outlier da regressão.\nO segundo gráfico, na direita superior, é chamado de (QQ plot), e é uma alternativa ao histograma para averiguar se há normalidade dos erros. Espera-se que, se a distribuição for normal, os pontos estarão próximos a uma reta. A observação 69 está bem longe dessa reta, colocando em dúvida a suposição de que os erros têm distribuição normal.\nO gráfico da esquerda inferior (Scale-Location) pode ser utilizado para averiguar se a variância é constante. Quando a variância é constante, a linha cinza-claro não apresenta oscilações significativas ao longo do eixo x.\nO gráfico inferior a direita (Residuals vs Leverage) nos ajuda a identificar pontos influentes na regressão. Utiliza-se como critério a distância de Cook.\nA distância de Cook mede o quanto determinada observação influência o resultado da regressão.\nPontos acima da linha tracejada inferior são considerados influentes, caso da observação 69.\nO script a seguir cria os gráficos para regressão linear simples com n=79, ou seja sem a observação 69, coniderada um outlier.\n\npar(mfrow=c(2,2))\nplot(Modelo2)"
  },
  {
    "objectID": "intro.html#modelo-de-regressão-múltipla",
    "href": "intro.html#modelo-de-regressão-múltipla",
    "title": "2  Regressão Linear",
    "section": "2.7 Modelo de Regressão Múltipla",
    "text": "2.7 Modelo de Regressão Múltipla\nGeralmente os modelos de regressão linear simples possuem alto erro padrão e baixo \\(R^{2}\\). Isso porque a variável Y(salário) é explicada por diversos fatores, não só pela idade do funcionário. Portanto, seria interessante utilizar mais de uma variável preditora no modelo para prever o salário com maior precisão.\nQuando há mais de uma variável preditora, temos o Modelo de Reressão Múltipla.\nEm termos gerais, um modelo de regressão linear múltipla é dado por:\n\\[ Y_{i} = \\beta_{0} + \\sum_{j=1}^{k} \\beta_{j} X_{ij}+\\epsilon_{i}\\]\nCom adição de variáveis ao modelo, espera-se que o \\(R^{2}\\) aumente consideravelmente. Na verdade, mesmo uma variável irrelevante para o modelo provocará um aumento (insignificante do \\(R^{2}\\)). Desta forma, não é recomendável utilizar o \\(R^{2}\\) para comparar um modelo com um variável preditora e outro modelo com duas preditoras. O modelo com duas preditoras sempre possuirá um \\(R^{2}\\) maior, principalmente se o número de variáveis prediotas for grande em comparação com o tamanho da amostra.\nO \\(R^{2}_{ajustado}\\) é uma medida que permite comparar modelos com diferentes tamanhos, pois para cada variável adicionada ao modelo a medida sofre uma penalização.\nO \\(R^{2}_{ajustado}\\) de um modelo com mais variáveis só aumentará se essa nova variável ajudar a prever o Y. Caso contrário, o \\(R^{2}_{ajustado}\\) pode diminuir em relação ao modelo sem tal variável.\nO modelo de regressão linear múltipla utilizará as variáveis: idade, tempo de casa, educação, cargo e local de trabalho para prever o salário.\nA função utilizada para rodar a regressão múltipla é a mesma que usamos para o modelo1 de regressão simples, mas agora colocaremos as variáveis preditoras após o “~” e separadas por “+”.\n\nModelo3 = lm(mercado2$SALARIO~mercado2$EDUCAÇÃO+mercado2$CARGO+mercado2$LOCAL+mercado2$IDADE+mercado2$TEMPOCASA)\nsummary(Modelo3)\n\n\nCall:\nlm(formula = mercado2$SALARIO ~ mercado2$EDUCAÇÃO + mercado2$CARGO + \n    mercado2$LOCAL + mercado2$IDADE + mercado2$TEMPOCASA)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-786.95 -246.45  -14.05  188.33 1315.44 \n\nCoefficients:\n                          Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)               3547.185    300.270  11.813  &lt; 2e-16 ***\nmercado2$EDUCAÇÃOSUPERIOR  128.199    108.170   1.185 0.239849    \nmercado2$CARGODIRETOR      737.071    143.260   5.145 2.22e-06 ***\nmercado2$CARGOGERENTE      345.073     93.222   3.702 0.000416 ***\nmercado2$LOCALINTERIOR     139.279     94.337   1.476 0.144198    \nmercado2$IDADE              18.689      7.306   2.558 0.012636 *  \nmercado2$TEMPOCASA          75.007      9.198   8.154 7.89e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 365.8 on 72 degrees of freedom\nMultiple R-squared:  0.8311,    Adjusted R-squared:  0.8171 \nF-statistic: 59.07 on 6 and 72 DF,  p-value: &lt; 2.2e-16\n\n\nNote que a saída do R para regressão múltipla é bem similar à da simples, A diferença é que agora há várias linhas, uma para cada variável independente, com suas estimativas, erros padrão, estatística t e valor-p."
  },
  {
    "objectID": "intro.html#interpretação-dos-coeficientes",
    "href": "intro.html#interpretação-dos-coeficientes",
    "title": "2  Regressão Linear",
    "section": "2.8 Interpretação dos Coeficientes",
    "text": "2.8 Interpretação dos Coeficientes\nO primeiro coeficiente, relativo a variável Educação, motra uma estimativa da diferença média entre os salários dos funcionários com nível superior e com nível secundário, mantida todas as variáveis constante. O valor estimado é 128,199. Entretanto, o erro padrão dessa estimativa é grande (108,17) e acarreta um valor-p alto = 0.23. Portanto, não conseguimos rejeitar a hipótese de que o coeficiente \\(\\beta_{1}\\) é diferente de zero. Desta forma, variável “Educação” não se mostrou significante no modelo, e será retirada.\nO segundo o terceiro coeficiente estão relacionados ao Cargo. O valor-p de ambas é muito baixo, menor que 0.0001, indicando fortes evidências estatísticas de que esses coeficientes na população são diferentes de zero.\nO quarto coeficiente, relativo a Local de Trabalho, assim como o primeiro, não é significante (valor-p = 0.14). Portanto, não há evidências estatísticas ao nível de 95% de significância de que os salários médios na capital e no interior são diferentes.\nO quinto coeficiente, relativo a Idade, mostra que o salário médio tem um aumento estimado de 18.68 por ano. Ao nível de significância de 0.05, podemos dizer que há evidências estatísticas de que o coeficiente na população é diferente de zero.\nO sexto coeficiente, relativo ao Tempo de Casa, indica que a cada ano dicional do funcionário no supermercado há um amento estimado no salário de 75,007 reais. Neste caso, conclui-se também que há evidências de que o coeficiente relativo ao tempo de casa na população \\(\\beta_{6}\\), é diferente de zero, pois valor-p &lt; 0.0001."
  },
  {
    "objectID": "intro.html#modelo-final",
    "href": "intro.html#modelo-final",
    "title": "2  Regressão Linear",
    "section": "2.9 Modelo Final",
    "text": "2.9 Modelo Final\nCom base no modelo anterior, verificou-se que, as variáveis: Nível Educacional e Local onde Atua o Funcionário não se mostraram estatisticamente significantes, com isso foram retirada na composição do modelo final.\nNote que o modelo final não fica guardado em nenhum objeto no R. È preciso rodar novamente apenas as variáveis selecionadas.\n\nModelo4 = lm(mercado2$SALARIO~+mercado2$CARGO+mercado2$IDADE+mercado2$TEMPOCASA)\nsummary(Modelo4)\n\n\nCall:\nlm(formula = mercado2$SALARIO ~ +mercado2$CARGO + mercado2$IDADE + \n    mercado2$TEMPOCASA)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-807.51 -215.10  -37.22  180.78 1274.19 \n\nCoefficients:\n                      Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)           3696.434    292.911  12.620  &lt; 2e-16 ***\nmercado2$CARGODIRETOR  673.404    137.882   4.884 5.84e-06 ***\nmercado2$CARGOGERENTE  326.859     93.630   3.491 0.000815 ***\nmercado2$IDADE          19.932      7.347   2.713 0.008292 ** \nmercado2$TEMPOCASA      72.340      9.001   8.037 1.10e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 369.7 on 74 degrees of freedom\nMultiple R-squared:  0.8227,    Adjusted R-squared:  0.8131 \nF-statistic: 85.84 on 4 and 74 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "intro.html#comparação-dos-modelos",
    "href": "intro.html#comparação-dos-modelos",
    "title": "2  Regressão Linear",
    "section": "2.10 Comparação dos Modelos",
    "text": "2.10 Comparação dos Modelos\n\nAIC(Modelo1,Modelo2, Modelo3, Modelo4)\n\n        df      AIC\nModelo1  3 1310.126\nModelo2  3 1216.318\nModelo3  8 1165.377\nModelo4  6 1165.234\n\nBIC(Modelo1,Modelo2, Modelo3, Modelo4)\n\n        df      BIC\nModelo1  3 1317.272\nModelo2  3 1223.426\nModelo3  8 1184.333\nModelo4  6 1179.451"
  },
  {
    "objectID": "intro.html#multicolinearidade",
    "href": "intro.html#multicolinearidade",
    "title": "2  Regressão Linear",
    "section": "2.11 Multicolinearidade",
    "text": "2.11 Multicolinearidade\nQuando uma variável preditora possui alta correlação com outras variáveis preditoras ou com uma combinação delas, temos um problema de multicolinearidade na regressão.\nQuando isso ocorre, as estimativas dos coeficientes apresentam alto erro padrão e geralmente são não significantes, tornando difícil avaliar o efeito de cada preditor no modelo.\nHá diversas formas de detectar multicolinearidade, sendo as mais utilizadas a Tolerância e o VIF(Variance inflation fator). Ambas baseiam-se em quanto uma variável preditora pode ser explicada pela combinação linear das outras variáveis preditoras.\nUma boa medida disto é o \\(R^{2}\\) da regressão em que a variável preditora “j” é explicada por todas as outras variáveis preditora. Um \\(R^{2}\\) alto indica multicolinearidade.\nA Tolerância e o VIF da variável preditora “j” são dados por:\n\\[ Tolerância = 1- R^{2}_{j}\\]\n\\[ VIF =  \\frac{1}{Tolerância} = \\frac{1}{1- R^{2}_{j}}\\]\nO cálculo do VIF na linguagem R pode ser feito utilizando o pacote car.\n\nlibrary(car)\nvif(Modelo3)\n\n                       GVIF Df GVIF^(1/(2*Df))\nmercado2$EDUCAÇÃO  1.062805  1        1.030925\nmercado2$CARGO     1.502308  2        1.107107\nmercado2$LOCAL     1.296742  1        1.138746\nmercado2$IDADE     2.859579  1        1.691029\nmercado2$TEMPOCASA 2.704690  1        1.644594\n\n\nVinhos que nenhuma variável possui VIF (ou GVIF) maior que 5, portanto, não temos problema de multicolinearidade no nosso modelo."
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "3  Regressão Logística",
    "section": "",
    "text": "A regressão logística permite estimar a probabilidade de que uma observação pertença a cada um \\(k\\) grupos (ou categorias) predeterminados. Posteriormente, podemos classificá-la em um desses grupos, de acordo com os valores dessas probabilidades.\nUm dos problemas operacionais mais complexos na aplicação da regressão logística é a diferenciação correta e clara dos dois grupos considerados, evitando qualquer tipo de ambiguidade.\nPor exemplo, no caso da análise de crédito, a definição do que seja um Bom ou um Mal Cliente é extremamente controversa."
  },
  {
    "objectID": "ridge.html#métodos-pra-determinar-k",
    "href": "ridge.html#métodos-pra-determinar-k",
    "title": "4  Regressão Ridge",
    "section": "4.1 Métodos pra Determinar \\(k\\)",
    "text": "4.1 Métodos pra Determinar \\(k\\)\nUm valor ideal para o parâmetro \\(K\\), o qual resulta em um menor QME que o obtido pelo Método de Mínimos Quadrados Ordinários (MQO) depende do vetor de parâmetro desconhecido e da variância do erro também desconhecido (HOERL; KENNARD, 1970a). Conseqüentemente, K precisa ser determinado empiricamente ou obtido dos dados, e não é possível determinar o valor ideal do parâmetro de cume K. Muitos métodos têm sido propostos para obter os valores apropriados, mas não existe um consenso de qual método é o mais adequado. Assim, o parâmetro de ridge \\(K\\) será estimado a partir de dois métodos: Gráfico do Traço de Cume (Ridge Trace Plot) e Gráfico do Fator de Inflação da Variância (Variance Inflation Factor Plot).\nUm dos obstáculos principais em utilizar a regressão de cume está em escolher um valor de k. O traço de cume é um esboço dos valores de (p-1) coeficientes estimados de regressão de cume padronizados para diferentes valores de \\(K\\), usualmente entre 0 e 1. Feito o traço, pode-se examinar um valor de \\(K\\) onde as estimativas se estabilizam. Hoerl e Kennard (1970b) desenvolveram um gráfico bidimensional do valor de cada coeficiente versus \\(k\\), mostrando como os valores de \\(\\hat{\\beta}\\) variam em função dos valores de k, ou seja, a partir do gráfico o analista escolhe um valor para K que os coeficientes da regressão tendem a ser mais precisos, que o MQO, quando os dados estão sob o efeito da multicolinearidade.\nSegundo Chagas et al. (2009), o objetivo é escolher um valor de k a partir do qual as estimativas dos parâmetros sejam relativamente estáveis gerando uma série de coeficientes com menor soma dos quadrados do resíduo do que a solução clássica. Assim, na medida em que se aumenta o valor de k, a soma de quadrados dos resíduos também aumentará, sugerindo iniciar com valores pequenos de k e ir aumentando gradativamente até que os coeficientes se estabilizem.\nPara Hoerl e Kennard (1970a), o Fator de Inflação da Variância, mostra a variabilidade em função do valor de K, ou seja, à medida que se atribui valores para K que estabilizam os coeficientes de regressão de cume, a variabilidade diminui, removendo a multicolinearidade. O traço do cume pode também ser usado para sugerir variável(s) que pode(m) ser retiradas do modelo. Algumas variáveis cuja estimativa do parâmetro é instável a cada mudança do valor de K ou que decresce para zero são candidatos para anulação.\nAtualmente na literatura, existem várias medidas corretivas para suavizar os efeitos provocados pela multicolinearidade, outros métodos são propostos desde simples as mais complexas, tais como, Ampliação do Tamanho da Amostra e Remoção das Variáveis (HAIR et al., 2005), utilização de Modelo de Regressão por Componente Principais (SILVA et al., 2009), Modelo de Regressão por Análise Fatorial (VALENTE et al., 2011), Regressão com Variáveis Latentes (MALHOTRA, 2011) e Regressão via Redes Neurais (RODRIGUES et al., 2010) e (LEAL et al., 2015).\nPara rodar a regressão Ridge na linguagem R, usaremos o pacote glmnet."
  },
  {
    "objectID": "lasso.html",
    "href": "lasso.html",
    "title": "5  Regressão LASSO",
    "section": "",
    "text": "A regressçao ridge mantém todas as variáveis no modelo final, memso quando \\(k\\) é grande. Isso pode ser um problema na interpretação do modelo, por conta da quantidade de variáveis e pelos baixos coeficientes. O lasso pe uma alternativa à regressão ridge que permite obter um modelo final com um subconjunto de variáveis.\nPara rodar a regressão Lasso na linguagem R, usaremos o pacote glmnet."
  }
]